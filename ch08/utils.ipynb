{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haru1489248/nlp-100-nock/blob/main/ch08/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF6NA4zSvFxE"
      },
      "source": [
        "## ch08で使用する共通の前処理をまとめる\n",
        "- wv = KeyedVectors.load_word2vec_format(...)\n",
        "- token2id / id2token / E の構築\n",
        "- filter_token, row_to_ids などの前処理関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6JvivaYvFSd",
        "outputId": "f5f2b916-3e1e-4097-d7e9-25b0508a273b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SgYmOFSFvOXh"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD6HiYZ6vn7Z",
        "outputId": "30fe2cdc-4ff8-4196-fa68-98db64a7b4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yLbPpOFJvdAa"
      },
      "outputs": [],
      "source": [
        "wv_src = '/content/drive/MyDrive/GoogleNews-vectors-negative300.bin.gz' # gzipはデータの中の繰り返しパターンを短い表現に置き換える\n",
        "wv = KeyedVectors.load_word2vec_format(wv_src, binary=True) # binary=Trueでバイナリ形式（0, 1のバイト列）で対応できるようにする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wJmCmlb2yBFj"
      },
      "outputs": [],
      "source": [
        "dev_src = \"/content/drive/MyDrive/SST-2/dev.tsv\"\n",
        "train_src = \"/content/drive/MyDrive/SST-2/train.tsv\"\n",
        "\n",
        "dev_df = pd.read_csv(dev_src, sep=\"\\t\")\n",
        "train_df = pd.read_csv(train_src, sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_token(row):\n",
        "  tokens = str(row['sentence']).split() # sentenceが欠損している場合を考えてstrで文字列変換し、NaNを空文字にしている\n",
        "  input_ids = []\n",
        "  for token in tokens:\n",
        "    if token in token2id:\n",
        "      input_ids.append(token2id[token])\n",
        "  return input_ids"
      ],
      "metadata": {
        "id": "kvkSL5L19UgU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def row_to_ids(row):\n",
        "  input_ids = filter_token(row)\n",
        "\n",
        "  if len(input_ids) == 0:\n",
        "    return None\n",
        "\n",
        "  return {\n",
        "      \"text\": row[\"sentence\"],\n",
        "      \"label\": torch.tensor([row[\"label\"]], dtype=torch.float32),\n",
        "      \"input_ids\": torch.tensor(input_ids, dtype=torch.long)\n",
        "  }"
      ],
      "metadata": {
        "id": "TWIWp1Es8NSC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YhGHv-BMwIxl"
      },
      "outputs": [],
      "source": [
        "def filter_token(row):\n",
        "  tokens = str(row['sentence']).split() # sentenceが欠損している場合を考えてstrで文字列変換し、NaNを空文字にしている\n",
        "  input_ids = []\n",
        "  not_found_count = 0\n",
        "  for token in tokens:\n",
        "    if token in token2id:\n",
        "      input_ids.append(token2id[token])\n",
        "  return input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JVfVnt5Cvl0k"
      },
      "outputs": [],
      "source": [
        "def row_to_ids(row):\n",
        "  input_ids = filter_token(row)\n",
        "\n",
        "  if len(input_ids) == 0:\n",
        "    return None\n",
        "\n",
        "  return {\n",
        "      \"text\": row[\"sentence\"],\n",
        "      \"label\": torch.tensor([row[\"label\"]], dtype=torch.float32),\n",
        "      \"input_ids\": torch.tensor(input_ids, dtype=torch.long)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivb_QmA2wFFT",
        "outputId": "8210c6a5-9f4e-4cbd-b36d-ffbb63f53c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "語彙数: 3000001\n",
            "埋め込み次元数 300\n",
            "(3000000, 300)\n",
            "3.3527612686157227\n"
          ]
        }
      ],
      "source": [
        "V = len(wv) + 1 # +1は<PAD>分\n",
        "print('語彙数:', V)\n",
        "\n",
        "d = wv.vector_size\n",
        "print('埋め込み次元数', d)\n",
        "\n",
        "print(wv.vectors.shape) # GoogleNews-vectors-negative300の埋め込み行列\n",
        "print(wv.vectors.nbytes / 1024**3) # 使用メモリ数\n",
        "E = torch.zeros((V, d), dtype=torch.float32) # PyTorchのニューラルネットが期待している型がfloat32らしい。今回は学習範囲外\n",
        "token2id = {\"<PAD>\": 0}\n",
        "id2token = [\"<PAD>\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VHeA1GIMwSXI"
      },
      "outputs": [],
      "source": [
        "for i, token in enumerate(wv.index_to_key, start=1): # すでに0のindexはPADに割り当てているので1から開始する\n",
        "  token2id[token] = i\n",
        "  id2token.append(token)\n",
        "  E[i] = torch.tensor(wv[token]) # from_numpyはnumpy配列をPyTorchテンソル型に変換する関数（torch.Tensor）"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df.apply(row_to_ids, axis=1).dropna()\n",
        "dev_data = dev_df.apply(row_to_ids, axis=1).dropna()"
      ],
      "metadata": {
        "id": "qc34WS759f5G"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOg5Odn+MMpsHThHgXboL9B",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}