{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haru1489248/nlp-100-nock/blob/main/ch08/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF6NA4zSvFxE"
      },
      "source": [
        "## ch08で使用する共通の前処理をまとめる\n",
        "- wv = KeyedVectors.load_word2vec_format(...)\n",
        "- token2id / id2token / E の構築\n",
        "- filter_token, row_to_ids などの前処理関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6JvivaYvFSd",
        "outputId": "5734eb56-da34-4d2e-9906-2113e796c543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgYmOFSFvOXh"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD6HiYZ6vn7Z",
        "outputId": "8636e526-256e-4317-b8f1-46b4f0a05750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLbPpOFJvdAa"
      },
      "outputs": [],
      "source": [
        "wv_src = '/content/drive/MyDrive/GoogleNews-vectors-negative300.bin.gz' # gzipはデータの中の繰り返しパターンを短い表現に置き換える\n",
        "wv = KeyedVectors.load_word2vec_format(wv_src, binary=True) # binary=Trueでバイナリ形式（0, 1のバイト列）で対応できるようにする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJmCmlb2yBFj"
      },
      "outputs": [],
      "source": [
        "dev_src = \"/content/drive/MyDrive/SST-2/dev.tsv\"\n",
        "train_src = \"/content/drive/MyDrive/SST-2/train.tsv\"\n",
        "\n",
        "dev_df = pd.read_csv(dev_src, sep=\"\\t\")\n",
        "train_df = pd.read_csv(train_src, sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhGHv-BMwIxl"
      },
      "outputs": [],
      "source": [
        "def filter_token(row):\n",
        "  tokens = str(row['sentence']).split() # sentenceが欠損している場合を考えてstrで文字列変換し、NaNを空文字にしている\n",
        "  input_ids = []\n",
        "  not_found_count = 0\n",
        "  for token in tokens:\n",
        "    if token in token2id:\n",
        "      input_ids.append(token2id[token])\n",
        "  return input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVfVnt5Cvl0k"
      },
      "outputs": [],
      "source": [
        "def row_to_ids(row):\n",
        "  input_ids = filter_token(row)\n",
        "\n",
        "  if len(input_ids) == 0:\n",
        "    return None\n",
        "\n",
        "  return {\n",
        "      \"text\": row[\"sentence\"],\n",
        "      \"label\": torch.tensor([row[\"label\"]], dtype=torch.float32),\n",
        "      \"input_ids\": torch.tensor(input_ids, dtype=torch.long)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivb_QmA2wFFT",
        "outputId": "1ec405a9-84bd-4c76-b24f-0427ca1d5a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "語彙数: 3000001\n",
            "埋め込み次元数 300\n",
            "(3000000, 300)\n",
            "3.3527612686157227\n"
          ]
        }
      ],
      "source": [
        "V = len(wv) + 1 # +1は<PAD>分\n",
        "print('語彙数:', V)\n",
        "\n",
        "d = wv.vector_size\n",
        "print('埋め込み次元数', d)\n",
        "\n",
        "print(wv.vectors.shape) # GoogleNews-vectors-negative300の埋め込み行列\n",
        "print(wv.vectors.nbytes / 1024**3) # 使用メモリ数\n",
        "E = torch.zeros((V, d), dtype=torch.float32) # PyTorchのニューラルネットが期待している型がfloat32らしい。今回は学習範囲外\n",
        "token2id = {\"<PAD>\": 0}\n",
        "id2token = [\"<PAD>\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VHeA1GIMwSXI"
      },
      "outputs": [],
      "source": [
        "for i, token in enumerate(wv.index_to_key, start=1): # すでに0のindexはPADに割り当てているので1から開始する\n",
        "  token2id[token] = i\n",
        "  id2token.append(token)\n",
        "  E[i] = torch.tensor(wv[token]) # from_numpyはnumpy配列をPyTorchテンソル型に変換する関数（torch.Tensor）"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSbbJme4DGBa0DYolsfc41",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}